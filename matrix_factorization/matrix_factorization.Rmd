---
title: "Matrix Factorization"
subtitle: "for Recommender systems"
author:
- name: Kyle Chung
  affiliation:
date: "`r format(Sys.time(), '%d %B %Y')` Last Updated"
output:
  html_notebook: 
    number_sections: yes
    theme: paper
    toc: yes
    toc_float: true
    highlight: pygments
  code_download: true
bibliography: matrix_factorization.bib
abstract: |
  TBC.
---

<!--For equation reference in Rmd.-->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

```{r setup, include=FALSE}
library(reticulate)
r <- try(use_python(Sys.getenv("PYTHON_PATH"), required=TRUE), silent=TRUE)
if ( is(r, "try-error") ) {
  r <- try(use_virtualenv(Sys.getenv("PYTHON_PATH"), required=TRUE), silent=TRUE)
  if ( is(r, "try-error") ) use_condaenv(Sys.getenv("PYTHON_PATH"), required=TRUE)
}
```

# The Task

Matrix factorization is a rather general term to describe a whole family of techniques aiming to solve a variety of problems.
In this notebook we are particularly interested in matrix factorization as a solution to a [recommender system](https://en.wikipedia.org/wiki/Recommender_system).
This means that we have a $m$ user by $n$ item matrix $R$ which records only the *observed* interaction between users and items.

Mathematically,
the problem is to approximately decompose a real (or binary) matrix $R_{m \times n}$ into a dot product of two matrices:

$$
\begin{equation}
{\underbrace{R_{m \times n} \vphantom{P_{k \times m}^T}}_\text{Interaction Matrix}}
\approx
{\underbrace{P_{k \times m}^T}_\text{User Matrix}}
\cdot
{\underbrace{Q_{k \times n} \vphantom{P_{k \times m}^T}}_\text{Item Matrix}}.
\end{equation}
$$

Matrix $R$ is usually very *sparse* due to the presence of a large amount of both users and items.
The dimension $k$ is a hyperparameter of the factorization model representing the length used to embed both users and items into real vectors.
That is,
each user and item is represented by a real vector of length $k$,
called the embedding,
and a dot product of a user embedding and an item embedding represents the interaction result of the given user-item pair.

In the rest of the notebook we will use the following notations for user embedding matrix

$$
P =
\begin{pmatrix} 
p_{11} & p_{12} & \dots \\
\vdots & \ddots & \vdots\\
p_{m1} & \dots  & p_{mk} 
\end{pmatrix}_{m \times k},
$$

and item embedding matrix:

$$
Q =
\begin{pmatrix}
q_{11} & q_{12} & \dots \\
\vdots & \ddots & \vdots \\
q_{n1} & \dots  & q_{nk} 
\end{pmatrix}_{n \times k}.
$$

For embedding vector $p_u$ representing individual user $u$

$$
p_u =
\begin{pmatrix} 
p_{u1} \\
\vdots \\
p_{uk} 
\end{pmatrix},
$$

and $q_i$ representing individual item $i$

$$
q_i =
\begin{pmatrix}
q_{i1} \\
\vdots \\
q_{ik}
\end{pmatrix}.
$$

The task is hence to learn the embeddings of all users and items such that their dot products can closely represent their corresponding observed interaction.^[By interaction, we mean a rating, a click, a like, or virtually anything that could happen for a pair of user and item.]

Our model weights to be learned are scalar values filled up all the embedding vectors for every user and item.
To learn all these weights,
we can formulate a general optimization problem:

$$
\begin{equation} \label{eq:mf_min}
\min_{P,Q} \sum_{u,i \in R} \bigg[
L(p_u, q_i, r_{ui}) + 
\underbrace{\lambda_p\vert\vert p_u \vert\vert^1 + \lambda_q\vert\vert q_i \vert\vert^1}_\text{L1 Regularization} +
\underbrace{\gamma_p\vert\vert p_u \vert\vert^2 + \gamma_q\vert\vert q_i \vert\vert^2}_\text{L2 Regularization}
\bigg],
\end{equation}
$$

where $u$ and $i$ are index of the $u$-th user and the $i$-th item in the matrix $R$,
$p_u$ is the user embedding vector for user $u$ and $q_i$ the item embedding vector for item $i$.
Function $L(\cdot)$ is a generic loss function depends on the embeddings and the actual interaction $r_{ui}$.
Constant $\lambda_*$ and $\gamma_*$ are (optional) hyperparameters for regularization.^[For a detailed discussion about regularization, one can refer to [this notebook](https://everdark.github.io/k9/neural_nets/neural_networks_fundamentals.nb.html#4_regularization).]

There is obviously no closed-form solution for the above problem.
But we can initialize the embeddings with random weights and apply numerical method such as [*gradient descent*](https://en.wikipedia.org/wiki/Gradient_descent) to approximate the solution.
One important trick in training the model is that,
the gradients are only calculated with respect to non-missing values in the interaction matrix.

# Learning Objectives

Before we actually solve the problem defined above,
we need to explicitly specify the loss function.
How should we pick up the loss function for the task in equation $\eqref{eq:mf_min}$?
It turns out that it really depends on what type of data we have and what kind of problem by nature we'd like to solve.
Generally speaking,
there are 3 types of interaction matrix we may encounter in a real-world problem:

1. Real-valued matrix: The interaction is well quantified, such as ratings, number of visits... 
2. Binary matrix: The interaction is a binary preference, such as like/dislike.
3. One-class matrix: The case of *implicit* feedback--only positive reactions are recorded.

The first two cases are sometimes referred to as explicit feedback.
The difference lies in how we interpret the missing values in the interaction matrix.
In implicit feedback,
a missing entry can be due to a user not like the item or doesn't know the item.
In general implicit feedback seems more plausible in real world and has become the mainstream approach for recommender systems.

For comepleteness we will still illustrate all 3 cases in the following sub-sections.

### Real Value Matrix Factorization {-}

When the interaction matrix records real-valued feedback such as a rating matrix,
it is natural to use the *squared error* as our loss:

$$
L(p_u, q_i, r_{ui}) = \sum_{u, i \in R} \big( r_{ui} - p_u^Tq_i \big)^2,
$$

where the model score for a user-item pair $(u, i)$ is

$$
p_u^Tq_i = \sum_{j=1}^kp_{uj} \cdot q_{ij}.
$$

The gradient w.r.t. model weights $p_{uk}$ and $q_{ik}$ for a user-item pair $(u, i)$ are quite straightforward:

$$
\begin{aligned}
\frac{\partial L(\cdot)}{\partial p_{uk}}
&= 2(r_{ui} - p_u^Tq_i) \cdot \frac{\partial p_u^Tq_i}{\partial p_{uk}} \\
&= 2(r_{ui} - p_u^Tq_i)q_{ik}, \\
\frac{\partial L(\cdot)}{\partial q_{ik}}
&= 2(r_{ui} - p_u^Tq_i) \cdot \frac{\partial p_u^Tq_i}{\partial q_{ik}} \\
&= 2(r_{ui} - p_u^Tq_i)p_{uk}.
\end{aligned}
$$

The following Python code is a toy implementation of such factorization model with L2 regularization:

```{python rvmf}
import numpy as np

def mf(R, k, n_step=5000, lr=.0003, l2=.04):
  tol = .001  # Tolerant loss.
  m, n = R.shape
  # Initialize the embedding weights.
  P = np.random.rand(m, k)
  Q = np.random.rand(n, k)
  for step in range(n_step):
    # Update weights by gradients.
    for u, i in zip(*R.nonzero()):
      err_ui = R[u,i] - P[u,:].dot(Q[i,:])
      for j in range(k):
        P[u][j] += lr * (2 * err_ui * Q[i][j] - l2/2 * P[u][j])
        Q[i][j] += lr * (2 * err_ui * P[u][j] - l2/2 * Q[i][j])
    # compute the loss.
    E = (R - P.dot(Q.T))**2
    obj = E[R.nonzero()].sum() + lr*((P**2).sum() +(Q**2).sum())
    if obj < tol:
        break
  return P, Q
```

Let's make an old Netflix-styled 5-star ratings and test our solver:^[Starting 2017 Netflix no longer uses 5-star rating any more but adopts a binary like/dislike interaction. The reason seems to be a higher user response rate which boost available interaction data.]

```{python rvmf_toy_data}
np.random.seed(777)

# Make missing more prevail.
stars = np.arange(6)
p = np.array([10, 1, 1, 1, 1, 1])
m = 5
n = 10

# A 5-star rating matrix.
ratings = np.random.choice(stars, size=m*n, p=p / p.sum()).reshape((m, n))
print(ratings)
```

```{python rvmf_toy_solution}
P, Q = mf(ratings, k=3)

print(P)  # User embeddings.

print(Q)  # Item embeddings.
```

The dot product of our estimated user and item embeddings should approximately resemble the original ratings whenever available:

```{python rvmf_toy_prediction_masked}
predictions = P.dot(Q.T)
mask = np.zeros_like(ratings)
mask[ratings.nonzero()] = 1

# Mask out unknown ratings as 0 for ease of comparison.
print(np.round(predictions * mask, 2))
```

And the dot products for missing entries serve as our model prediction to the unknown user-item interaction:

```{python rvmf_toy_prediction}
# Mask out known ratings as 0 for ease of comparison.
print(np.round(predictions * (1 - mask), 2))
```

Since now every user and item is represented by a real vector,
given a user and a list of items we can generate the recommended items orderd by predicted model score.

Our simple educational implementation won't scale as the dimension of interaction matrix grows.
Fortunately the algorithm can speed up considerably by parallel computing.
@chin2015fast gives a very good review on different strategies of parallellization on gradient descent for matrix factorization problem.

#### Automatic Differentiation {-}

To save our ass in later illustration let's use `tensorflow` (@tensorflow2015-whitepaper) to implement the factorization model.
`tensorflow` is a powerful framework designed for [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) that helps compute gradients at scale.
Though our implementation will still be trivial without much engineering optimization,
by using automatic differentiation we can skip the manual derivation and hardcoding of our gradient function.

```{python import_tensorflow}
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)

import tensorflow as tf
print(tf.__version__)
```

```{python rvmf_tf}
class MatrixFactorization:
  def __init__(self, R, k, lr=.0003, l2=.04, seed=777):
    self.R = tf.convert_to_tensor(R, dtype=tf.float32)
    self.mask = tf.not_equal(self.R, 0)
    self.m, self.n = R.shape
    self.k = k
    self.lr = lr
    self.l2 = l2
    self.tol = .001
    # Initialize trainable weights.
    self.weight_init = tf.random_normal_initializer(seed=seed)
    self.P = tf.Variable(self.weight_init((self.m, self.k)))
    self.Q = tf.Variable(self.weight_init((self.n, self.k)))

  def loss(self):
    raise NotImplementedError

  def grad_update(self):
    with tf.GradientTape() as t:
      t.watch([self.P, self.Q])
      self.current_loss = self.loss()
    gP, gQ = t.gradient(self.current_loss, [self.P, self.Q])
    self.P.assign_sub(self.lr * gP)
    self.Q.assign_sub(self.lr * gQ)

  def train(self, n_step=5000):
    for step in range(n_step):
      self.grad_update()
      if self.current_loss < self.tol:
        break


class RealValueMF(MatrixFactorization):
  # The implementation is far from optimized since we don't need the product of entire P'Q.
  # We only need scores for non-missing entries.
  # The code is hence for educational purpose only.
  def loss(self):
    """Squared error loss."""
    E = (self.R - tf.matmul(self.P, self.Q, transpose_b=True))**2
    l2_norm = tf.reduce_sum(self.P**2) + tf.reduce_sum(self.Q**2)
    out = tf.reduce_sum(tf.boolean_mask(E, self.mask)) + self.l2 * l2_norm
    return out
```

```{python rvmf_tf_prediction}
rvmf_model = RealValueMF(ratings, k=3)
rvmf_model.train()

predictions = tf.matmul(rvmf_model.P, rvmf_model.Q, transpose_b=True).numpy()
print(np.round(predictions * mask, 2))
```

### Binary Matrix Factorization {-}

When the user-item interaction is a binary outcome ($r_{ui} \in \{0, 1\}$),
it is natural to use [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) as our loss function for the optimization problem in $\eqref{eq:mf_min}$.
That is,

$$
L(p_u, q_i, r_{ui}) = \sum_{u, i \in R} \bigg[
r_{ui}\log (p_u^Tq_i) + (1 - r_{ui}) \log (1 - p_u^Tq_i)
\bigg].
$$

```{python bmf_toy_data}
# Make missing more prevail.
responses = [-1, 0, 1]
p = np.array([1, 5, 1])
m = 5
n = 10

# A binary response matrix.
b_ratings = np.random.choice(responses, size=m*n, p=p / p.sum()).reshape((m, n))
print(b_ratings)
```

```{python bmf_tf}
class BinaryMF(MatrixFactorization):
  def train(self, n_step=5000):
    # Cast 1/-1 as binary encoding of 0/1.
    self.labels = tf.cast(tf.not_equal(tf.boolean_mask(self.R, self.mask), -1), dtype=tf.float32)
    for step in range(n_step):
      self.grad_update()

  # The implementation is far from optimized since we don't need the product of entire P'Q.
  # We only need scores for non-missing entries.
  # The code is hence for educational purpose only.
  def loss(self):
    """Cross entropy loss."""
    logits = tf.boolean_mask(tf.matmul(self.P, self.Q, transpose_b=True), self.mask)
    logloss = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.labels, logits=logits)
    mlogloss = tf.reduce_mean(logloss)
    l2_norm = tf.reduce_sum(self.P**2) + tf.reduce_sum(self.Q**2)
    return mlogloss + self.l2 * l2_norm
```


```{python bmf_tf_prediction_masked}
# We increase the learning a bit since logloss has a very different scale than squared error.
# For the same reason we decrease the L2 coefficient.
bmf_model = BinaryMF(b_ratings, k=3, lr=.03, l2=.0001)
bmf_model.train()

b_predictions = tf.sigmoid(tf.matmul(bmf_model.P, bmf_model.Q, transpose_b=True)).numpy()

b_mask = np.zeros_like(b_ratings)
b_mask[b_ratings.nonzero()] = 1

# Check prediction on training entries.
print(np.round(b_predictions * b_mask, 2))
```

#### Linkage to Neural Netorks {-}


### One-Class Matrix Factorization {-}

#### Bayesian Personalized Ranking {-}

For the case of an implicit feedback matrix,
@rendle2009bpr proposed the idea of "Bayesian personalized ranking" which is widely used in many recommender system framework.

#### Logistic Matrix Factorization {-}

@hu2008collaborative

@johnson2014logistic propose the idea of logisitic matrix factorization.





# Efficient Implementations

Package [`libmf`](https://github.com/cjlin1/libmf) (@chin2016libmf) is an extremely efficient C++ implementation of matrix factorization utilizing parallel computing in cpu.
It also supports on-disk data parsing for large scale application where the training data cannot fit in local memory.




# References

